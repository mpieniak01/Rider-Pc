[capture]
device = "wm8960_in"
sample_rate = 16000
channels = 1
sample_format = "S16_LE"

[playback]
backend = "aplay"
device  = "wm8960_out"
volume  = 55

[asr]
backend = "local"
base_url = "http://127.0.0.1:8092"
endpoint = "/api/asr"
content_type = "audio/wav"
language = "pl"
timeout = 8

[chat]
backend = "local"
model = "small"
system_prompt = "Jesteś asystentem głosowym Rider-Pi. Odpowiadaj krótko po polsku."
transport = "file"
max_history = 4
max_tokens = 512
base_url = "http://127.0.0.1:8092"
endpoint = "/api/chat"
timeout = 20.0

# --- NOWE KLUCZE (dla serwera apps/voice/web.py) ---
# Ścieżka do skompilowanej binarki llama.cpp (np. pobranej z tutoriali RPi)
# Wartość domyślna, jeśli nie ustawiona w ~/.bash_profile
llm_main_path = "llama.cpp/build/bin/llama-cli"

# Ścieżka do modelu GGUF. Rekomendowany model dla RPi to Phi-3-mini.
# Zalecana domyślna ścieżka:
llm_model_path = "models/llm/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"

# Dodatkowe flagi dla llama.cpp (wątki, rozmiar kontekstu itp.)
# -t 4 = 4 wątki (dla RPi 4/5)
# --simple-io = unika logów startowych w stdout
llm_extra_args = "-t 4 -n 128 --ctx-size 512 --simple-io --temp 0.7"

[tts]
backend = "local"
voice = "pl_PL-gosia-medium"
model   = "small"
format  = "wav"
accept  = "audio/wav"
base_url = "http://127.0.0.1:8092"
endpoint = "/api/tts"
timeout  = 10
transport = "file"

[nlu]
backend = "passthrough"
chat_threshold = 0.4
llm_model = "none"
command_keywords = { stop = ["stop","pauza","cisza"] }

[hotword]
enabled = false
engine  = "none"

[ptt]
commit_on_stop = true
silence_ms = 800
max_turn_ms = 20000

# VAD — czulszy próg energii i dłuższy ogon ciszy
[vad]
enabled = true
engine = "webrtc"
mode = 2
frame_ms = 20
tail_ms = 500
energy_gate_dbfs = -38.0
max_len_ms = 5000

[service]
beep = false
pre_speech_wait_ms = 350
mic_open_delay_ms = 30
post_tts_mute_ms = 200
min_capture_ms = 1200
no_speech_timeout_ms = 3500
silence_rms_gate = 260
save_audio = false
recordings_dir = "/tmp/voice-recs"

[save_audio]
enabled = false
dir = "./recordings"

[logging]
level = "INFO"
json = false
sink = "stderr"

[compat]
allow_unknown_keys = true
